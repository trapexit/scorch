#!/usr/bin/env python3

# ISC License (ISC)
#
# Copyright (c) 2016, Antonio SJ Musumeci <trapexit@spawn.link>
#
# Permission to use, copy, modify, and/or distribute this software for any
# purpose with or without fee is hereby granted, provided that the above
# copyright notice and this permission notice appear in all copies.
#
# THE SOFTWARE IS PROVIDED "AS IS" AND THE AUTHOR DISCLAIMS ALL WARRANTIES
# WITH REGARD TO THIS SOFTWARE INCLUDING ALL IMPLIED WARRANTIES OF
# MERCHANTABILITY AND FITNESS. IN NO EVENT SHALL THE AUTHOR BE LIABLE FOR
# ANY SPECIAL, DIRECT, INDIRECT, OR CONSEQUENTIAL DAMAGES OR ANY DAMAGES
# WHATSOEVER RESULTING FROM LOSS OF USE, DATA OR PROFITS, WHETHER IN AN
# ACTION OF CONTRACT, NEGLIGENCE OR OTHER TORTIOUS ACTION, ARISING OUT OF
# OR IN CONNECTION WITH THE USE OR PERFORMANCE OF THIS SOFTWARE.

import argparse
import errno
import hashlib
import math
import os
import pickle
import random
import re
import shlex
import stat
import subprocess
import sys
import tempfile
import time


DEFAULT_DB = '/var/tmp/scorch.db'

# Define a compact version of stat object for serialization
class CompactStat(object):
    st_mode = 0
    st_size = 0
    st_mtime = 0

    # class constructor
    def __init__(self,mode,size,mtime):
        self.st_mode = mode
        self.st_size = size
        self.st_mtime = mtime

def build_arg_parser():
    desc = 'a tool to help discover file corruption'
    parser = argparse.ArgumentParser(description=desc)
    parser.add_argument('-d','--db',
                        type=str,
                        default=DEFAULT_DB,
                        help='database which stores hashes')
    parser.add_argument('inst',
                        choices=['add','append','check',
                                 'check+update','delete',
                                 'cleanup','list',
                                 'list-unhashed','list-dups',
                                 'list-missing','find'],
                        help='actions')
    parser.add_argument('dir',
                        type=str,
                        nargs='+',
                        help='directories to work on')
    parser.add_argument('-v','--verbose',
                        action='store_true',
                        help='print details of files')
    parser.add_argument('-r','--restrict',
                        choices=['sticky',
                                 'readonly'],
                        help='restrict action to certain types of files')
    parser.add_argument('-f','--fnfilter',
                        type=str,
                        help='restrict action to files which match regex')
    parser.add_argument('-s','--sort',
                        choices=['none','radix','reverse-radix',
                                 'natural','reverse-natural','random'],
                        help='when adding/appending/checking sort files before acting on them')
    parser.add_argument('-m','--max',
                        type=int,
                        default=sys.maxsize,
                        help='max number of actions to take')
    parser.add_argument('-b','--break-on-error',
                        action='store_true',
                        default=False,
                        help='break on first failure / error')

    return parser


def hash_file(filepath, hasher=None, blocksize=65536):
    if not hasher:
        hasher = hashlib.md5()

    with open(filepath,'rb') as afile:
        buf = afile.read(blocksize)
        while buf:
            hasher.update(buf)
            buf = afile.read(blocksize)

    return hasher.hexdigest()


def get_file_list(basepath,fnfilter,db=None):
    if os.path.isfile(basepath):
        return [basepath]

    filelist = []
    for (dirname,dirnames,filenames) in os.walk(basepath):
        fulldirpath = os.path.join(basepath,dirname)
        for filename in filenames:
            filepath = os.path.join(fulldirpath,filename)
            if fnfilter(filepath):
                continue
            if db and filepath in db:
                continue
            filelist.append(filepath)
    return filelist


def filter_filepaths(filepaths,basepath,fnfilter,other=(lambda f: False)):
    if basepath in filepaths:
        return [basepath]

    rv = []
    for filepath in filepaths:
        if not filepath.startswith(basepath):
            continue
        if fnfilter(filepath):
            continue
        if other(filepath):
            continue
        rv.append(filepath)

    return rv


def get_stat(filepath):
    try:
        st = os.lstat(filepath)
        if not stat.S_ISREG(st.st_mode):
            return None
        return st
    except:
        return None


def print_filepath(count,total,filepath):
    padding = len(str(total))
    padded = str(count).zfill(padding)
    s = '{0}/{1} {2}: '.format(padded,total,filepath)
    print(s,end='')
    sys.stdout.flush()


def humansize(nbytes):
    suffixes = ['B','KB','MB','GB','TB','PB','ZB']
    rank = int(math.log(nbytes,1024))
    rank = min(rank, len(suffixes) - 1)
    human = nbytes / (1024.0 ** rank)
    f = ('%.2f' % human).rstrip('0').rstrip('.')
    return '%s%s' % (f, suffixes[rank])


# Can't use inode since filesystems based on FUSE can have those change
# mount to mount
def different_files(oldst,newst):
    return ((oldst.st_size  != newst.st_size) and
            (oldst.st_mtime != newst.st_mtime))


def add_hashes(db,basepath,restrict,fnfilter,sort,
               maxactions,verbose,breakonerror,
               dbadd,dbremove):
    rv = 1
    filepaths = get_file_list(basepath,fnfilter)
    sort(filepaths)

    actions = 0
    total = min(maxactions,len(filepaths))
    for filepath in filepaths:
        st = get_stat(filepath)
        if not st:
            continue
        if not restrict(st):
            continue

        if actions >= maxactions:
            return rv
        actions += 1

        rv = 0
        if verbose:
            print_filepath(actions,total,filepath)

        try:
            hashval = hash_file(filepath)
            dbadd[filepath] = (hashval,st.st_mode,st.st_size,st.st_mtime)
            if verbose:
                print(hashval)
        except Exception as e:
            if verbose:
                print("ERROR:",e)
            if breakonerror:
                break

    return rv


def append_hashes(db,basepath,restrict,fnfilter,sort,
                  maxactions,verbose,breakonerror,
                  dbadd,dbremove):
    rv = 1
    filepaths = get_file_list(basepath,fnfilter,db)
    sort(filepaths)

    actions = 0
    total = min(maxactions,len(filepaths))
    for filepath in filepaths:
        st = get_stat(filepath)
        if not st:
            continue
        if not restrict(st):
            continue

        if actions >= maxactions:
            return rv
        actions += 1

        rv = 0
        if verbose:
            print_filepath(actions,total,filepath)

        try:
            hashval = hash_file(filepath)
            dbadd[filepath] = (hashval,st.st_mode,st.st_size,st.st_mtime)
            if verbose:
                print(hashval)
        except (KeyboardInterrupt,SystemExit):
            raise
        except Exception as e:
            if verbose:
                print(e)
            if breakonerror:
                break

    return rv


def check_hashes(db,basepath,restrict,fnfilter,sort,
                 maxactions,verbose,breakonerror,
                 dbadd,dbremove,update=False):
    rv = 0
    filepaths = filter_filepaths(db.keys(),basepath,fnfilter)
    sort(filepaths)

    actions = 0
    total = min(maxactions,len(filepaths))
    for filepath in filepaths:
        st = get_stat(filepath)
        if not st:
            continue
        if not restrict(st):
            continue

        if actions >= maxactions:
            return rv
        actions += 1

        if verbose:
            print_filepath(actions,total,filepath)

        try:
            oldst = CompactStat(db[filepath][1], db[filepath][2], db[filepath][3])
            if different_files(oldst,st):
                if not verbose:
                    print_filepath(actions,total,filepath)
                old_size = humansize(oldst.st_size)
                new_size = humansize(st.st_size)
                old_time = time.ctime(oldst.st_mtime)
                new_time = time.ctime(st.st_mtime)
                print("FILE CHANGED\n",
                      "- size:",old_size,"->",new_size,"\n"
                      " - mtime:",old_time,"->",new_time)
                if update:
                    hashval = hash_file(filepath)
                    dbadd[filepath] = (hashval,st.st_mode,st.st_size,st.st_mtime)
                    print(" - updated hash:",hashval)
            else:
                hashval = hash_file(filepath)
                oldhashval = db[filepath][0]
                if hashval != oldhashval:
                    rv = 1
                    if not verbose:
                        print_filepath(actions,total,filepath)
                    print("FAILED")
                    if breakonerror:
                        break
                elif verbose:
                    print("OK")
        except (KeyboardInterrupt,SystemExit):
            raise
        except Exception as e:
            if not verbose:
                print_filepath(actions,total,filepath)
            print('ERROR:',e)
            if breakonerror:
                break

    return rv


def check_and_update_hashes(db,basepath,restrict,fnfilter,sort,
                            maxactions,verbose,breakonerror,
                            dbadd,dbremove):
    return check_hashes(db,basepath,restrict,fnfilter,sort,
                        maxactions,verbose,breakonerror,
                        dbadd,dbremove,update=True)


def delete_hashes(db,basepath,restrict,fnfilter,sort,
                  maxactions,verbose,breakonerror,
                  dbadd,dbremove):
    rv = 1
    filepaths = filter_filepaths(db.keys(),basepath,fnfilter)
    sort(filepaths)

    actions = 0
    total = min(maxactions,len(filepaths))
    for filepath in filepaths:
        st = get_stat(filepath)
        if st and not restrict(st):
            continue

        if actions >= maxactions:
            return rv
        actions += 1

        rv = 0
        dbremove.append(filepath)
        if verbose:
            print_filepath(actions,total,filepath)
            print("removed")

    return rv


def cleanup_hashes(db,basepath,restrict,fnfilter,sort,
                   maxactions,verbose,breakonerror,
                   dbadd,dbremove):
    rv = 1
    filepaths = filter_filepaths(db.keys(),basepath,fnfilter,os.path.exists)
    sort(filepaths)

    actions = 0
    total = min(maxactions,len(filepaths))
    for filepath in filepaths:
        if actions >= maxactions:
            return rv
        actions += 1

        rv = 0
        dbremove.append(filepath)
        if verbose:
            print_filepath(actions,total,filepath)
            print("removed")

    return rv


def list_hashes(db,basepath,restrict,fnfilter,sort,
                maxactions,verbose,breakonerror,
                dbadd,dbremove):
    rv = 1
    filepaths = filter_filepaths(db.keys(),basepath,fnfilter)
    sort(filepaths)

    actions = 0
    for filepath in filepaths:
        (hashval,st_mode,st_size,st_mtime) = db[filepath]

        st = CompactStat(st_mode,st_size,st_mtime)

        if not restrict(st):
            continue

        if actions >= maxactions:
            return rv
        actions += 1

        rv = 0
        print("{0} {1}".format(hashval,filepath))

    return rv


def list_unhashed(db,basepath,restrict,fnfilter,sort,
                  maxactions,verbose,breakonerror,
                  dbadd,dbremove):
    rv = 1
    filepaths = get_file_list(basepath,fnfilter,db)
    sort(filepaths)

    actions = 0
    for filepath in filepaths:
        st = get_stat(filepath)
        if not st:
            continue
        if not restrict(st):
            continue

        if actions >= maxactions:
            return rv
        actions += 1

        rv = 0
        print(filepath)

    return rv


def list_dups(db,basepath,restrict,fnfilter,sort,
              maxactions,verbose,breakonerror,
              dbadd,dbremove):
    rv = 1
    hashdb = {}
    for (filepath,(hashval,st_mode,st_size,st_mtime)) in db.items():

        st = CompactStat(st_mode,st_size,st_mtime)

        if not filepath.startswith(basepath):
            continue
        if fnfilter(filepath):
            continue
        if not restrict(st):
            continue

        if not hashval in hashdb:
            hashdb[hashval] = [filepath]
            continue

        hashdb[hashval].append(filepath)

    actions = 0
    for (hashval,filepaths) in hashdb.items():
        if len(filepaths) <= 1:
            continue

        if actions >= maxactions:
            return rv
        actions += 1

        rv = 0
        filepaths = [shlex.quote(filepath) for filepath in filepaths]
        filepaths.sort()
        print(hashval,' '.join(filepaths))

    return rv


def list_missing(db,basepath,restrict,fnfilter,sort,
                 maxactions,verbose,breakonerror,
                 dbadd,dbremove):
    rv = 1
    filepaths = get_file_list(basepath,fnfilter)

    actions = 0
    output  = []
    for (filepath,(hashval,st_mode,st_size,st_mtime)) in db.items():

        st = CompactStat(st_mode,st_size,st_mtime)

        if not filepath.startswith(basepath):
            continue
        if fnfilter(filepath):
            continue
        if filepath in filepaths:
            continue

        if actions >= maxactions:
            return rv
        actions += 1

        rv = 0
        output.append(filepath)

    sort(output)
    for filepath in output:
        print(filepath)

    return rv


def find(db,basepath,restrict,fnfilter,sort,
         maxactions,verbose,breakonerror,
         dbadd,dbremove):
    rv = 1
    hashdb = {}
    for (filepath,(hashval,st_mode,st_size,st_mtime)) in db.items():

        if not hashval in hashdb:
            hashdb[hashval] = [filepath]
            continue
        hashdb[hashval].append(filepath)

    actions = 0
    filepaths = get_file_list(basepath,fnfilter)
    for filepath in filepaths:
        try:
            if actions >= maxactions:
                return rv;

            st = get_stat(filepath)
            if not st:
                continue
            if not restrict(st):
                continue

            hashval = hash_file(filepath)
            if hashval not in hashdb:
                continue

            rv = 0
            actions += 1

            files = ' '.join([shlex.quote(f) for f in hashdb[hashval]])
            quoted_filepath = shlex.quote(filepath)
            if verbose:
                print(hashval,quoted_filepath,files)
            else:
                print(quoted_filepath)
        except Exception as e:
            print("ERROR:",e)

    return rv


def is_sticky(st):
    return bool(st.st_mode & stat.S_ISVTX)


def is_readonly(st):
    return not (st.st_mode & (stat.S_IWUSR | stat.S_IWGRP | stat.S_IWOTH))


def restrict_fun(rtype):
    if rtype == 'sticky':
        return is_sticky
    elif rtype == 'readonly':
        return is_readonly
    return (lambda st: True)


def filter_fun(regex):
    if regex:
        cregex = re.compile(regex)
        return (lambda filepath: cregex.match(filepath) == None)
    return (lambda filepath: False)


def inst_fun(inst):
    if inst == 'add':
        return add_hashes
    elif inst == 'append':
        return append_hashes
    elif inst == 'check':
        return check_hashes
    elif inst == 'check+update':
        return check_and_update_hashes
    elif inst == 'delete':
        return delete_hashes
    elif inst == 'cleanup':
        return cleanup_hashes
    elif inst == 'list':
        return list_hashes
    elif inst == 'list-unhashed':
        return list_unhashed
    elif inst == 'list-dups':
        return list_dups
    elif inst == 'list-missing':
        return list_missing
    elif inst == 'find':
        return find
    return None


def sort_fun(sort):
    if sort == 'radix':
        return (lambda l: l.sort())
    elif sort == 'reverse-radix':
        return (lambda l: l.sort(reverse=True))
    elif sort == 'random':
        return (lambda l: random.shuffle(l))
    elif sort == 'natural':
        cre = re.compile('(\d+)')
        sort_key = lambda s: [int(t) if t.isdigit() else t.lower()
                              for t in re.split(cre,s)]
        return (lambda l: l.sort(key=sort_key))
    elif sort == 'reverse-natural':
        cre = re.compile('(\d+)')
        sort_key = lambda s: [int(t) if t.isdigit() else t.lower()
                              for t in re.split(cre,s)]
        return (lambda l: l.sort(key=sort_key,reverse=True))
    return (lambda l: None)


def read_db(filepath):
    db = {}
    try:
        with open(filepath,'rb') as f:
            db = pickle.load(f)
    except (KeyboardInterrupt,SystemExit):
        raise
    except Exception as e:
        dirname = os.path.dirname(filepath)
        if not os.path.isdir(dirname):
            raise
    return db

def write_db(db,filepath,dbadd,dbremove):
    try:

        for (k,v) in dbadd.items():
            db[k] = v;
        for k in dbremove:
            del db[k]

        basepath = os.path.dirname(filepath)
        (fd,tmpfilepath) = tempfile.mkstemp(dir=basepath)
        with os.fdopen(fd,'wb') as f:
            pickle.dump(db,f)
        if os.name == 'nt' and os.path.isfile(filepath):
            os.remove(filepath) # Windows: Remove the db file before for no [WinError 183] (Cannot create a file when that file already exists)
        os.rename(tmpfilepath,filepath)
    except (KeyboardInterrupt,SystemExit):
        raise
    except Exception as e:
        print('Error writing checksum DB:',e)


def process_directories(dirs):
    rv = []
    for d in dirs:
        realpath = os.path.realpath(d)
        if realpath != '/':
            realpath + os.path.sep
        rv.append(realpath)
    return rv


def main():
    parser = build_arg_parser()
    args   = parser.parse_args()

    dbpath       = os.path.realpath(args.db)
    verbose      = args.verbose
    restrict     = restrict_fun(args.restrict)
    func         = inst_fun(args.inst)
    sort         = sort_fun(args.sort)
    fnfilter     = filter_fun(args.fnfilter)
    maxactions   = args.max
    breakonerror = args.break_on_error
    directories  = process_directories(args.dir)

    rv = 0
    try:
        for directory in directories:
            db = read_db(dbpath)
            dbadd = {}
            dbremove = []

            rv = rv or func(db,directory,restrict,fnfilter,sort,
                            maxactions,verbose,breakonerror,
                            dbadd,dbremove)

            if len(dbadd) or len(dbremove):
                write_db(db,dbpath,dbadd,dbremove)

            if breakonerror and rv:
                break

    except (KeyboardInterrupt,SystemExit):
        rv = 1
    except IOError as e:
        rv = 1
        if e.errno != errno.EPIPE:
            print(e)
    except Exception as e:
        rv = 1
        print(e)

    sys.exit(rv)


if __name__ == "__main__":
    main()
